{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyb2Tj8Vniqi"
   },
   "source": [
    "## Dataset Information\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "np.random.seed(43)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "4pcHuoxeoDh8",
    "outputId": "b40964da-464a-49a1-b71e-41924935f503"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "hour = 60*60\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Non-Fraud vs Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Relation with Time and fraud\n",
    "- 1시간 간격에 따른 Fraud 비율의 분포(조건부 분포)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 거래 내역에 있어서 Time(hour)의 분포\n",
    "- time_group 1 ~ 9, 25 ~ 33이 밤, 새벽 시간대인 것으로 추정됨\n",
    "- 위 아래의 그래프를 종합하면, 새벽 시간대에 사기 거래가 발생할 확률이 높다고 추론할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time 변수 전처리\n",
    "- 1. 하루 24 * 60 * 60 초를 mod로 하여 변환 - y과 time의 관계가 비선형임을 참고\n",
    "\n",
    "\n",
    "\n",
    "밑의 2,3 과정은 train set에 대해 oversampling 적용한 다음 train, validation, test set에 일괄적으로 진행\n",
    "- 2. 1시간 단위로 그룹화한 다음, 24mod 적용 - 그룹화했을 뿐, 여전히 y와 time의 관계가 비선형\n",
    "- 3. 2시간 단위로 그룹화한 다음, 12mod를 적용한 후, dummy변수로 펼침 - Lasso와 같이 비선형을 잡아내지 못하는 모형을 돌릴 때 추천(2시간 단위로 그래프를 보면 더욱 매끄러워서 2시간으로 그룹화함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Time_1hour : 2번\\ndf['Time_1hour'] = pd.cut(df['Time'], bins, right=False, labels = list(range(1, len(bins),1)))\\ndf['Time_1hour'] = df['Time_1hour'].astype(int)\\ndf.loc[df.Time_1hour>24, 'Time_1hour'] = df.loc[df.Time_1hour>24, 'Time_1hour']-24\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Time_1hour : 2번\n",
    "df['Time_1hour'] = pd.cut(df['Time'], bins, right=False, labels = list(range(1, len(bins),1)))\n",
    "df['Time_1hour'] = df['Time_1hour'].astype(int)\n",
    "df.loc[df.Time_1hour>24, 'Time_1hour'] = df.loc[df.Time_1hour>24, 'Time_1hour']-24\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# two_hour_1, two_hour_2, two_hour_3,,,, two_hour12 : 3번\\nbins = list(range(int(min(df['Time'])), int(max(df['Time']))+9, hour*2))\\ndf['two_hour'] = pd.cut(df['Time'], bins, right=False, labels = list(range(1, len(bins), 1)))\\ndf['two_hour'] = df['two_hour'].astype(int)\\ndf.loc[df.two_hour>12, 'two_hour'] = df.loc[df.two_hour>12, 'two_hour']-12\\ndf = pd.get_dummies(df, columns = ['two_hour'])\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# two_hour_1, two_hour_2, two_hour_3,,,, two_hour12 : 3번\n",
    "bins = list(range(int(min(df['Time'])), int(max(df['Time']))+9, hour*2))\n",
    "df['two_hour'] = pd.cut(df['Time'], bins, right=False, labels = list(range(1, len(bins), 1)))\n",
    "df['two_hour'] = df['two_hour'].astype(int)\n",
    "df.loc[df.two_hour>12, 'two_hour'] = df.loc[df.two_hour>12, 'two_hour']-12\n",
    "df = pd.get_dummies(df, columns = ['two_hour'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time_sec : 1번\n",
    "df.loc[df.Time>=(hour)*24, 'Time'] = df.loc[df.Time>=(hour)*24, 'Time']-(hour*24)\n",
    "df = df.rename(columns={\"Time\":\"Time_sec\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. About PCs(V1, V2, .. V28)\n",
    "### 3-1. feature 간 상관관계\n",
    "- Principal components(V1~V28) 간에 상관관계는 없다.\n",
    "- 몇몇 PC는 Time, Amount와 유의미한 상관관계를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Distributions of V1, V2,,,, on y=0 and y=1 \n",
    "- y를 예측하는데 의미없어보이는 변수들도 있어 보인다 : V13, V15, V22, V24, V25, V26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_kde(data : pd.DataFrame):\n",
    "\n",
    "    pc = [\"V\"+str(i) for i in range(1,29)]\n",
    "\n",
    "    i = 0\n",
    "    c0 = data.loc[data['Class'] == 0]\n",
    "    c1 = data.loc[data['Class'] == 1]\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(7,4,figsize=(16,28))\n",
    "\n",
    "    for feature in pc:\n",
    "        i += 1\n",
    "        plt.subplot(7,4,i)\n",
    "        sns.kdeplot(c0[feature], bw=0.5, label=\"Class = 0\")\n",
    "        sns.kdeplot(c1[feature], bw=0.5, label=\"Class = 1\")\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Conditional Probabilty of y over V1, V2,,,\n",
    "- 특정 변수에서 특정 구간에 속할 경우, fraud일 확률이 급격히 올라감을 알 수 있다.\n",
    "- 단순한 선형모형으로는 좋은 분류 모델을 만들기 어려울 것으로 판단된다.\n",
    "- 만약 overfitting이 문제가 된다면, 아래 분포 중 극단적인 분포를 갖는 feature에서 이상치를 제거해야 할 것이다. 심지어 중간 값을 빼줘야 할지도 모른다. 특정 구간에서 y=1일 확률이 1.0에 가깝게 판단이 되는 이유는 특정 구간에 속한 데이터가 몇 개 안 되는 데 그 몇 개 안 되는 데이터가 모두 y=1이기 때문이다. 이게 유용한 단서가 될수도, Overfitting을 야기할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpd_set(interval:int):\n",
    "    df_copy = df.copy()\n",
    "    pc = [\"V\"+str(i) for i in range(1,29)]\n",
    "    i=0\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(7,4, figsize=(16,28))\n",
    "    \n",
    "    for feature in pc : \n",
    "        i +=1\n",
    "        \n",
    "        a = max(df_copy[feature])\n",
    "        b = min(df_copy[feature])\n",
    "        diff = a-b\n",
    "        size = diff/(interval-1)\n",
    "        extra = diff*0.0001\n",
    "        intervals = np.arange(b, a+extra, size)\n",
    "        intervals[0] -=extra\n",
    "        intervals[len(intervals)-1] += extra\n",
    "        df_copy[feature+'_group'] = pd.cut(df_copy[feature], intervals, right=False, labels = list(range(1, len(intervals), 1)))\n",
    "        dist = df_copy.groupby(feature+'_group')[\"Class\"].mean()\n",
    "        dist = pd.DataFrame(dist)\n",
    "        dist.reset_index(drop = False, inplace = True)\n",
    "        \n",
    "        plt.subplot(7,4,i)\n",
    "        plt.plot(dist[feature+'_group'], dist['Class'], 'g.-')\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        plt.yticks(np.arange(0,1.01,0.2))\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. About Amount\n",
    "### 4-1. 기초 통계량 & Dist of Amount on y=1 and y=0\n",
    "- 사기거래의 거래금액이 평균적으로 크다.\n",
    "- 그러나 거래금액이 크다고 사기거래일 확률이 높아지는 것이 아니다.\n",
    "- 그래프를 통해 알 수 있듯이, 1000\\\\$ 정도가 넘어가는 거래는 대부분 정상거래이다. 특히 사기거래의 Max Amount는 2126\\\\$ 이다.\n",
    "- 다만 정상거래는 Amount가 낮은 경우가 압도적으로 많기 때문에 정상거래의 거래금액 평균이 낮아진 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Conditional probabilty of y=1 over Transaction Amount\n",
    "- 거래 금액이 일정 수준 클 경우, 오히려 사기거래일 확률이 급격히 떨어짐을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cpd(feature:str, interval_number:int ):\n",
    "    a = max(df[feature])\n",
    "    b = min(df[feature])\n",
    "    diff = a-b\n",
    "    size = diff/(interval_number-1)\n",
    "    extra = diff*0.0001\n",
    "    intervals = np.arange(b, a+extra, size)\n",
    "    intervals[0] -=extra\n",
    "    intervals[len(intervals)-1] += extra\n",
    "    df_copy = df.copy()\n",
    "    df_copy[feature+'_group'] = pd.cut(df_copy[feature], intervals, right=False, labels = list(range(1, len(intervals), 1)))\n",
    "    dist = df_copy.groupby(feature+'_group')[\"Class\"].mean()\n",
    "    dist = pd.DataFrame(dist)\n",
    "    dist.reset_index(drop = False, inplace = True)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.title('Conditional probability of y on '+feature, fontdict={'fontweight':'bold', 'fontsize': 18})\n",
    "    plt.plot(dist[feature+'_group'], dist.Class, 'g.-')\n",
    "    plt.xlabel(feature+'_group')\n",
    "    plt.ylabel('Probability of y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. 로그변환\n",
    "- 위의 Distribution of Transaction Amount 그래프에서 볼 수 있듯이, right-skewed 된 분포이다.\n",
    "- 따라서 표준화하기 전에 로그변환으로 치우친 정도를 완화시키자. \n",
    "- Amount = 0인 거래의 경우, 0.001로 대체한다. 0 다음으로 작은 Amount가 0.25이니, 0을 0.001로 대체해도 큰 무리는 없을 것으로 판단된다.\n",
    "- 다만 Amount = 0인 거래가 특별한 의미가 있을 수 있어서, 논의가 필요해보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Amount']==0, 'Amount'] = 0.001\n",
    "\n",
    "df['Amount'] = np.log(df['Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 결측치 확인 & 이상치 처리\n",
    "- 결측치 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. 이상치에 관한 의사결정\n",
    "- log 변환 이후 Amount 분포를 살펴본 결과, Amount의 이상치는 제거하지 않기로 결정\n",
    "- Principle components(V1, V2,,,)의 이상치가 class 0, 1을 분류하는데 결정적인지 분포를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = [\"V\"+str(i) for i in range(1,29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot_dot(data : pd.DataFrame):\n",
    "\n",
    "    pc = [\"V\"+str(i) for i in range(1,29)]\n",
    "\n",
    "    i = 0\n",
    "    c0 = data.loc[data['Class'] == 0]\n",
    "    c1 = data.loc[data['Class'] == 1]\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(7,4,figsize=(25,25))\n",
    "\n",
    "    for feature in pc:\n",
    "        i += 1\n",
    "        plt.subplot(7,4,i)\n",
    "        sns.scatterplot(x=feature, y=[0]*len(c0), data=c0, alpha=0.5, label=\"Class=0\")\n",
    "        sns.scatterplot(x=feature, y=[1]*len(c1), data=c1, alpha=0.5, label=\"Class=1\")\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        plt.yticks([0,1])\n",
    "        \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 몇몇 feature에서 class=0에서 과한 이상치들이 관측된다(e.g. V27, V28, V7)\n",
    "- 20*iqr을 기준으로 하여 이상치를 upper bound, lower bound로 대치하기로 결정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in pc:\n",
    "    q1 = np.percentile(df[feature], 25)\n",
    "    q3 = np.percentile(df[feature], 75)\n",
    "    iqr = q3-q1\n",
    "    threshold = 20* iqr\n",
    "    upper = q3+threshold\n",
    "    lower = q1-threshold\n",
    "    df.loc[df[feature]>upper, feature] = upper\n",
    "    df.loc[df[feature]<lower, feature] = lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time_sec', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9',\n",
       "       'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
       "       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27',\n",
       "       'V28', 'Amount', 'Class'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LASSO로 변수의 유의성 판단\n",
    "- 비선형적인 관계는 제대로 포착하지 못한다는 명백한 한계가 있지만, 그래도 돌려보자\n",
    "- time 변수는 더미변수 버전(two_hour1, 2,,,) 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Standard Scaling\n",
    "- V1,, V28 : PCA 과정에서 이미 수행됨\n",
    "- Amount : log 변환을 통해 어느정도 scaling이 이루어졌다고 판단\n",
    "- Time : 필요시, oversampling 이후에 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data split & OverSampling\n",
    "\n",
    "### 8-1. Train : Test = 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "x_train = train.drop(['Class'],axis = 1)\n",
    "y_train = train['Class']\n",
    "x_test = test.drop(['Class'], axis=1)\n",
    "y_test = test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-2. Oversampling 수행\n",
    "- highly imbalanced data set -> OverSampling for better model\n",
    "- Oversampling function : V1~V28은 정규분포를 따른다고 가정(LLN) ->               각 열마다 minority class에서의 정규분포에서 랜덤 샘플링\n",
    "- time의 경우 V1,V2,,, 들과 어느정도 상관관계를 지님. 따라서 독립적으로 뽑지 않고, time_sec를 선형회귀분석으로 예측해서 채움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def over_sampling(X_set, y_set, r = 1):\n",
    "    \n",
    "    data_df = pd.concat([X_set, y_set], axis=1)\n",
    "\n",
    "    y_predict_time = X_set['Time_sec']\n",
    "    x_predict_time = X_set.drop([\"Time_sec\"],axis = 1)\n",
    "    x_predict_time[\"Class\"] = y_set\n",
    "    \n",
    "    linear = LinearRegression(fit_intercept=True)\n",
    "    linear.fit(x_predict_time,y_predict_time)\n",
    "    \n",
    "    n = len(data_df.loc[data_df['Class'] == 0])\n",
    "    k1 = len(data_df.loc[data_df['Class'] == 1])\n",
    "    k2 = math.ceil(n*r)-k1\n",
    "\n",
    "    m = len(data_df['Class'])\n",
    "    t1 = data_df.loc[data_df['Class'] == 1]\n",
    "    col_list = list(data_df.columns)\n",
    "    df_sample = pd.DataFrame([], index = range(m,m+k2))\n",
    "    col_list.remove(\"Time_sec\")\n",
    "    for col in col_list:\n",
    "        mu = t1[col].mean()\n",
    "        sig = t1[col].std()\n",
    "        \n",
    "        df_sample[col] = np.random.normal(loc = mu, scale = sig, size = k2)\n",
    "    \n",
    "    predicted_time = linear.predict(df_sample)\n",
    "    df_sample[\"Time_sec\"] = predicted_time\n",
    "    df_sample[\"Time_sec\"] = df_sample[\"Time_sec\"].astype(int)\n",
    "    df_sample['Time_sec'] %= (60*60)*24\n",
    "    df_sample['Class'] = 1\n",
    "        \n",
    "    \n",
    "    merged_df = pd.concat([data_df, df_sample])\n",
    "    X_sample = merged_df.drop([\"Class\"], axis = 1)\n",
    "    y_sample = merged_df[\"Class\"]\n",
    "    \n",
    "    return (X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = over_sampling(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-3. Oversampling 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-4. Time에 대한 추가적인 전처리\n",
    "\n",
    "- 위에서 설명했던 2번, 3번에 대한 코드\n",
    "- Time_1hour : 1시간 단위로 그룹화한 다음, 24mod 적용 - 그룹화했을 뿐, 여전히 y와 time의 관계가 비선형\n",
    "- two_hour 더미변수 : 2시간 단위로 그룹화한 다음, 12mod를 적용한 후, dummy변수로 펼침 - Lasso와 같이 비선형을 잡아내지 못하는 모형을 돌릴 때 추천(2시간 단위로 그래프를 보면 더욱 매끄러워서 2시간으로 그룹화함)\n",
    "- 모델에 맞게 Time_sec, Time_1hour, two_hour 중 하나 사용\n",
    "- Time_sec나 Time_1hour를 활용한다면, Time_sec에 한해서만 standard scaling 할 것을 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time_sec를 사용할 경우(Default), standard scaling\n",
    "sc = StandardScaler()\n",
    "train_time, test_time = pd.DataFrame(x_train['Time_sec']), pd.DataFrame(x_test['Time_sec'])\n",
    "\n",
    "\n",
    "x_train['Time_sec'], x_test['Time_sec'] = sc.fit_transform(train_time), sc.fit_transform(test_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhour = 60*60\\nbins = list(range(0, 86401, hour))\\n\\nx_train['Time_1hour'] = pd.cut(x_train['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\\nx_train['Time_1hour'] = x_train['Time_1hour'].astype(int)\\nx_train.drop(['Time_sec'], axis=1, inplace = True)\\n\\nx_test['Time_1hour'] = pd.cut(x_test['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\\nx_test['Time_1hour'] = x_test['Time_1hour'].astype(int)\\nx_test.drop(['Time_sec'], axis=1, inplace = True)\\n\\n\\nsc = StandardScaler()\\ntrain_time, test_time = pd.DataFrame(x_train['Time_1hour']), pd.DataFrame(x_test['Time_1hour'])\\nx_train['Time_1hour'], x_test['Time_1hour'] = sc.fit_transform(train_time), sc.fit_transform(test_time)\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time_1hour 사용할 경우 & standard scaling\n",
    "'''\n",
    "hour = 60*60\n",
    "bins = list(range(0, 86401, hour))\n",
    "\n",
    "x_train['Time_1hour'] = pd.cut(x_train['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\n",
    "x_train['Time_1hour'] = x_train['Time_1hour'].astype(int)\n",
    "x_train.drop(['Time_sec'], axis=1, inplace = True)\n",
    "\n",
    "x_test['Time_1hour'] = pd.cut(x_test['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\n",
    "x_test['Time_1hour'] = x_test['Time_1hour'].astype(int)\n",
    "x_test.drop(['Time_sec'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_time, test_time = pd.DataFrame(x_train['Time_1hour']), pd.DataFrame(x_test['Time_1hour'])\n",
    "x_train['Time_1hour'], x_test['Time_1hour'] = sc.fit_transform(train_time), sc.fit_transform(test_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhour = 60*60\\nbins = list(range(0, 86401, hour*2))\\n\\nx_train['two_hour'] = pd.cut(x_train['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\\nx_train['two_hour'] = x_train['two_hour'].astype(int)\\nx_train.drop(['Time_sec'], axis=1, inplace = True)\\nx_train = pd.get_dummies(x_train, columns=['two_hour'])\\n\\nx_test['two_hour'] = pd.cut(x_test['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\\nx_test['two_hour'] = x_test['two_hour'].astype(int)\\nx_test.drop(['Time_sec'], axis=1, inplace = True)\\nx_test = pd.get_dummies(x_test, columns=['two_hour'])\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#two_hour 더미변수를 time feature로 사용할 경우\n",
    "#two_hour_1, two_hour_2, two_hour_3,,,, two_hour12\n",
    "'''\n",
    "hour = 60*60\n",
    "bins = list(range(0, 86401, hour*2))\n",
    "\n",
    "x_train['two_hour'] = pd.cut(x_train['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\n",
    "x_train['two_hour'] = x_train['two_hour'].astype(int)\n",
    "x_train.drop(['Time_sec'], axis=1, inplace = True)\n",
    "x_train = pd.get_dummies(x_train, columns=['two_hour'])\n",
    "\n",
    "x_test['two_hour'] = pd.cut(x_test['Time_sec'], bins, right=False, labels = list(range(1, len(bins), 1)))\n",
    "x_test['two_hour'] = x_test['two_hour'].astype(int)\n",
    "x_test.drop(['Time_sec'], axis=1, inplace = True)\n",
    "x_test = pd.get_dummies(x_test, columns=['two_hour'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-5. Oversampling 다른 방식\n",
    "- SMOTE\n",
    "- RandomOversampler\n",
    "- 8-2 코드 대신 SMOTE와 RandomOversampler 중 하나를 정해 실행시킨 후, 8-3부터 8-4까지 코드 그대로 실행시키면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Define the oversampler\\noversampler = RandomOverSampler(sampling_strategy='minority')\\n\\n#SMOTE\\noversampler = SMOTE()\\n\\n''' \\nkind: A string parameter that specifies the type of SMOTE to use. The options are 'regular', 'borderline1', 'borderline2', 'svm', or 'all'. The default is 'regular'.\\nout_step: A float parameter that specifies the step size when interpolating new samples. The default is 0.5.\\nm_neighbors: An integer parameter that specifies the number of nearest neighbors to use when selecting minority class samples to oversample. The default is 5.\\nsvm_estimator: An object parameter that specifies the estimator object used for the SVM-based SMOTE variant. The default is None.\\nn_jobs: The number of CPU cores to use for parallelization. The default is 1.\\nverbose: A verbosity level for logging. The default is 0.\\n'''\\n\\n# Fit and transform the data\\nx_train, y_train = oversampler.fit_resample(x_train, y_train)\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the oversampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "#SMOTE\n",
    "oversampler = SMOTE()\n",
    "\n",
    "''' \n",
    "kind: A string parameter that specifies the type of SMOTE to use. The options are 'regular', 'borderline1', 'borderline2', 'svm', or 'all'. The default is 'regular'.\n",
    "out_step: A float parameter that specifies the step size when interpolating new samples. The default is 0.5.\n",
    "m_neighbors: An integer parameter that specifies the number of nearest neighbors to use when selecting minority class samples to oversample. The default is 5.\n",
    "svm_estimator: An object parameter that specifies the estimator object used for the SVM-based SMOTE variant. The default is None.\n",
    "n_jobs: The number of CPU cores to use for parallelization. The default is 1.\n",
    "verbose: A verbosity level for logging. The default is 0.\n",
    "'''\n",
    "\n",
    "# Fit and transform the data\n",
    "x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
